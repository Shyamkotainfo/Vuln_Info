import requests
import time
from datetime import datetime
from ...base import BaseExtractor

class NVDExtractor(BaseExtractor):
    def __init__(self, api_key=None):
        super().__init__("NVD")
        self.base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.api_key = api_key
        self.delay = 0.6 if api_key else 6.0 

    def extract(self, since=None):
        """
        Extracts NVD data.
        :param since: ISO8601 string for lastModStartDate (e.g., '2024-01-01T00:00:00.000')
        """
        return self.extract_all_concurrent(since=since)

    def extract_from_api(self, start_index=0, limit=2000, since=None):
        headers = {}
        if self.api_key:
            headers['apiKey'] = self.api_key

        params = {
            'resultsPerPage': limit,
            'startIndex': start_index
        }
        
        if since:
            params['lastModStartDate'] = since
            # NVD requires an end date if start date is provided, usually max 120 days range? 
            # Actually for 2.0 API, lastModEndDate is optional but if omitted it defaults to current time? 
            # Wait, NVD API 2.0 limitation: can't do large ranges without end date or tight windows?
            # Let's check docs strictly. Actually, usually it's better to just pass lastModStartDate.
            # However, if the range is too large, it might error? NVD docs say: 
            # "The maximum time range is 120 days." -> THIS IS CRITICAL.
            # If we are doing "incremental" and the gap is > 120 days, we might fail.
            # For this simplified implementation, we assume incremental runs are frequent (daily).
            # If `since` is very old, we might need a different strategy (chunking by date).
            # For now, let's assume `since` is passed correctly.
            from datetime import timedelta
            # We strictly set end date to now to define the window
            params['lastModEndDate'] = datetime.utcnow().isoformat()

        try:
            print(f"Fetching startIndex={start_index}, limit={limit}...")
            response = requests.get(self.base_url, headers=headers, params=params, timeout=60)
            
            if response.status_code == 429:
                print(f"Rate limit hit at startIndex={start_index}. Retrying after sleep...")
                time.sleep(10)
                return self.extract_from_api(start_index, limit, since)

            response.raise_for_status()
            data = response.json()
            return data.get('vulnerabilities', []), data.get('totalResults', 0)
        except Exception as e:
            print(f"Error extracting NVD data at index {start_index}: {e}")
            return [], 0
    
    def extract_all_concurrent(self, batch_size=2000, max_workers=5, since=None):
        import concurrent.futures
        
        first_batch, total_results = self.extract_from_api(start_index=0, limit=1, since=since)
        if total_results == 0:
            print("No new NVD results found.")
            return

        print(f"Total NVD CVEs to fetch: {total_results}")
        
        offsets = range(0, total_results, batch_size)
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_offset = {executor.submit(self.extract_from_api, offset, batch_size, since): offset for offset in offsets}
            
            for future in concurrent.futures.as_completed(future_to_offset):
                offset = future_to_offset[future]
                try:
                    data, _ = future.result()
                    if data:
                        yield data
                    time.sleep(self.delay) 
                except Exception as exc:
                    print(f"Batch starting at {offset} generated an exception: {exc}")
