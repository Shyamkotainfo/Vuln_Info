import argparse
import sys
import logging
from datetime import datetime

# Setup Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("pipeline.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("pipeline.orchestrator")

# Import Sources
from .datasources.external_feeds.nvd.extract import NVDExtractor
from .datasources.external_feeds.nvd.load import NVDLoader
from .datasources.external_feeds.cisa.extract import CISAExtractor
from .datasources.external_feeds.cisa.load import CISALoader
from .datasources.external_feeds.epss.extract import EPSSExtractor
from .datasources.external_feeds.epss.load import EPSSLoader
from .datasources.external_feeds.exploit.extract import ExploitDBExtractor
from .datasources.external_feeds.exploit.load import ExploitDBLoader
from .datasources.external_feeds.metasploit.extract import MetasploitExtractor
from .datasources.external_feeds.metasploit.load import MetasploitLoader

from .core.config import Config

class PipelineOrchestrator:
    def __init__(self):
        self.sources = {
            "nvd": {"extractor": NVDExtractor(api_key=Config.NVD_API_KEY), "loader": NVDLoader(), "key": "lastModified"},
            "cisa": {"extractor": CISAExtractor(), "loader": CISALoader(), "key": "dateAdded"}, # or catalogVersion
            "epss": {"extractor": EPSSExtractor(), "loader": EPSSLoader(), "key": "date"},
            "exploit": {"extractor": ExploitDBExtractor(), "loader": ExploitDBLoader(), "key": "date_published"},
            "metasploit": {"extractor": MetasploitExtractor(), "loader": MetasploitLoader(), "key": "mod_time"},
        }

    def run_pipeline(self, source_keys=None, mode="full"):
        """
        Runs the pipeline for specified sources.
        :param source_keys: List of source names to run (e.g. ['nvd', 'cisa']). None for all.
        :param mode: 'full' or 'incremental'.
        """
        keys_to_run = source_keys if source_keys else self.sources.keys()
        
        for key in keys_to_run:
            if key not in self.sources:
                logger.warning(f"Unknown source: {key}")
                continue
            
            logger.info(f"--- Starting {key.upper()} Pipeline ({mode}) ---")
            components = self.sources[key]
            extractor = components["extractor"]
            loader = components["loader"]
            max_key_field = components["key"]
            
            since = None
            if mode == "incremental":
                # Determine max key from DB
                since = loader.get_max_key(max_key_field)
                if since:
                    logger.info(f"Incremental Load: Fetching entries > {since}")
                else:
                    logger.info("Incremental Load: No existing data found. Switching to full load logic (fetching all).")
            
            try:
                # Extract returns a generator/iterator
                data_generator = extractor.extract(since=since)
                
                # Load consumes the iterator
                loader.load(data_generator)
                
            except Exception as e:
                logger.error(f"Pipeline failed for {key}: {e}", exc_info=True)
            
            logger.info(f"--- Completed {key.upper()} Pipeline ---")

def main():
    parser = argparse.ArgumentParser(description="Vulnerability ETL Pipeline Orchestrator")
    parser.add_argument("--sources", nargs="+", help="Specific sources to run (nvd, cisa, epss, exploit, metasploit)")
    parser.add_argument("--mode", choices=["full", "incremental"], default="full", help="Load mode")
    
    args = parser.parse_args()
    
    orchestrator = PipelineOrchestrator()
    orchestrator.run_pipeline(source_keys=args.sources, mode=args.mode)

if __name__ == "__main__":
    main()
