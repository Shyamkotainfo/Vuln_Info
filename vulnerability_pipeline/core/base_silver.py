import logging
import pymongo
from datetime import datetime
from ..core.config import Config
from ..core.mongo_client import MongoManager

class BaseSilverPipeline:
    def __init__(self, source_collection, target_collection, bronze_key, silver_key):
        """
        :param source_collection: Name of Bronze collection (e.g., 'nvd_cves_raw')
        :param target_collection: Name of Silver collection (e.g., 'nvd_silver')
        :param bronze_key: Field in Bronze to use for incremental check (e.g., 'lastModified')
        :param silver_key: Field in Silver that maps to bronze_key (e.g., 'last_modified')
        """
        # Connect to respective DBs
        self.source_db = MongoManager.get_bronze_db()
        self.target_db = MongoManager.get_silver_db()
        
        self.source_col = self.source_db[source_collection]
        self.target_col = self.target_db[target_collection]
        
        self.bronze_key = bronze_key
        self.silver_key = silver_key
        
        self.logger = logging.getLogger(f"pipeline.silver.{target_collection}")
        
        # Ensure index on target PK (created by child classes usually, but good to have)
        self._ensure_indexes()

    def _ensure_indexes(self):
        """Override to create specific indexes."""
        pass

    def get_last_watermark(self):
        """Get the max value of silver_key from target collection."""
        try:
            # Sort descending and get first
            record = self.target_col.find_one(sort=[(self.silver_key, pymongo.DESCENDING)])
            if record:
                return record.get(self.silver_key)
        except Exception as e:
            self.logger.error(f"Error getting watermark: {e}")
        return None

    def transform(self, bronze_doc):
        """
        Override this method.
        Input: Plain dict from Bronze.
        Output: Transformed dict for Silver. Access nested fields safely.
        """
        raise NotImplementedError

    def run(self):
        self.logger.info(f"Starting Silver ETL for {self.target_col.name}")
        
        # 1. Get Watermark
        last_val = self.get_last_watermark()
        query = {}
        if last_val:
            self.logger.info(f"Resuming from {self.silver_key} > {last_val}")
            query = {self.bronze_key: {"$gt": last_val}}
        else:
            self.logger.info("Full load (no existing watermark).")

        # 2. Fetch from Bronze
        cursor = self.source_col.find(query)
        total_bronze = self.source_col.count_documents(query)
        self.logger.info(f"Docs to process: {total_bronze}")

        # 3. Process
        ops = []
        BATCH_SIZE = 500
        count = 0
        
        for doc in cursor:
            try:
                transformed = self.transform(doc)
                if not transformed:
                    continue
                    
                # Add ETL Metadata
                transformed['silver_updated_at'] = datetime.utcnow()
                # silver_created_at handled via $setOnInsert usually, or we just rely on updated_at
                
                # CRUD Operation
                # We need the PK for the filter. Child class should define keys? 
                # Let's assume transformed dict has the PK.
                # We'll expect the child to return (pk_field_name, pk_value, doc) or just doc and we deduce?
                # Better: transform returns the FULL document ready for insertion.
                # But we need the PK for 'update'. 
                # Helper method needed.
                ops.append(self._build_upsert_op(transformed))
                
                if len(ops) >= BATCH_SIZE:
                    self._write_batch(ops)
                    count += len(ops)
                    ops = []
                    
            except Exception as e:
                self.logger.error(f"Error transforming doc {doc.get('_id')}: {e}")

        if ops:
            self._write_batch(ops)
            count += len(ops)
            
        self.logger.info(f"Silver Load Complete. Processed {count} records.")

    def _build_upsert_op(self, doc):
        """
        Override or implement generic logic.
        Default: assume '_id' is the PK.
        """
        # If child ensures '_id' is set to the PK (e.g. cveID), this works.
        return pymongo.UpdateOne(
            {"_id": doc["_id"]}, 
            {"$set": doc, "$setOnInsert": {"silver_created_at": datetime.utcnow()}}, 
            upsert=True
        )
            
    def _write_batch(self, ops):
        if not ops:
            return
        try:
            res = self.target_col.bulk_write(ops, ordered=False)
            # self.logger.info(f"Batch wrote: {res.bulk_api_result}") 
        except Exception as e:
            self.logger.error(f"Bulk write error: {e}")
